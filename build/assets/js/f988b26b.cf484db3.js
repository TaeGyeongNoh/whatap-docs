"use strict";(self.webpackChunkWhaTap_Docs=self.webpackChunkWhaTap_Docs||[]).push([[34716],{39416:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>a});var t=s(74848),i=s(28453);const r={id:"nvidia-gpu",title:"Supporting the NVIDIA GPU",description:"It provides the method how to collect GPU data of the Kubernetes agent.",tags:["Kubernetes","Kubernetes Monitoring","Support Environment","GPU"]},o=void 0,l={id:"kubernetes/nvidia-gpu",title:"Supporting the NVIDIA GPU",description:"It provides the method how to collect GPU data of the Kubernetes agent.",source:"@site/i18n/en/docusaurus-plugin-content-docs/current/kubernetes/nvidia-gpu.mdx",sourceDirName:"kubernetes",slug:"/kubernetes/nvidia-gpu",permalink:"/kubernetes/nvidia-gpu",draft:!1,unlisted:!1,editUrl:"undefined/docs/kubernetes/nvidia-gpu.mdx",tags:[{inline:!0,label:"Kubernetes",permalink:"/tags/kubernetes"},{inline:!0,label:"Kubernetes Monitoring",permalink:"/tags/kubernetes-monitoring"},{inline:!0,label:"Support Environment",permalink:"/tags/support-environment"},{inline:!0,label:"GPU",permalink:"/tags/gpu"}],version:"current",frontMatter:{id:"nvidia-gpu",title:"Supporting the NVIDIA GPU",description:"It provides the method how to collect GPU data of the Kubernetes agent.",tags:["Kubernetes","Kubernetes Monitoring","Support Environment","GPU"]},sidebar:"kubeSidebar",previous:{title:"Support environment for Kubernetes Monitoring",permalink:"/kubernetes/supported-spec"},next:{title:"Agent Installation",permalink:"/kubernetes/install"}},c={},a=[{value:"How to collect GPU metrics of the WhaTap Kubernetes agent",id:"how-to-collect-gpu-metrics-of-the-whatap-kubernetes-agent",level:2},{value:"Collection scope",id:"collection-scope",level:2},{value:"Collection metrics",id:"collection-metrics",level:2},{value:"Node level metrics",id:"node-level-metrics",level:3},{value:"Container level metrics",id:"container-level-metrics",level:3}];function d(e){const n={admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",section:"section",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.section,{className:"remark-sectionize-h2",children:[(0,t.jsx)(n.h2,{id:"how-to-collect-gpu-metrics-of-the-whatap-kubernetes-agent",children:"How to collect GPU metrics of the WhaTap Kubernetes agent"}),(0,t.jsx)(n.p,{children:"The WhaTap Kubernetes node agent collects and monitors performance metrics of the NVIDIA GPU by using the Data Center GPU Manager (DCGM) Exporter. The process is structured using the Sidecar pattern."}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Sidecar pattern"})}),"\n",(0,t.jsx)(n.p,{children:"The DCGM Exporter is set as a secondary container that runs within the same Pod together with the main application container. This Sidecar pattern helps the DCGM Exporter efficiently collect the GPU status information."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"DCGM Exporter"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"dcgm-exporter"})," container collects GPU status and performance metrics via NVIDIA's Data Center GPU Manager (DCGM)."]}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Metric collection and transmission"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"whatap-node-agent"})," container requests and collects GPU metrics via the HTTP endpoint of ",(0,t.jsx)(n.code,{children:"dcgm-exporter"}),"."]}),"\n",(0,t.jsxs)(n.admonition,{type:"note",children:[(0,t.jsx)(n.mdxAdmonitionTitle,{}),(0,t.jsxs)(n.p,{children:["The HTTP endpoint of ",(0,t.jsx)(n.code,{children:"dcgm-exporter"})," usually uses the port 9400."]})]}),"\n"]}),"\n"]})]}),"\n",(0,t.jsxs)(n.section,{className:"remark-sectionize-h2",children:[(0,t.jsx)(n.h2,{id:"collection-scope",children:"Collection scope"}),(0,t.jsx)(n.p,{children:"The WhaTap Kubernetes agent focuses on efficiently monitoring and managing the GPU usage of each container deployed on the node."}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Containers"})}),"\n",(0,t.jsx)(n.p,{children:"The WhaTap node agent collects GPU metrics for each container, giving you a clear view of how much GPU resources each container is using. This data is useful for optimizing the resource allocation."}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Nodes"})}),"\n",(0,t.jsx)(n.p,{children:"You can monitor GPU usage across the entire node to assess the GPU resource utilization for the entire node. This information is useful for analyzing the overall performance of the cluster, but does not provide the details at the individual process level."}),"\n"]}),"\n"]})]}),"\n",(0,t.jsxs)(n.section,{className:"remark-sectionize-h2",children:[(0,t.jsx)(n.h2,{id:"collection-metrics",children:"Collection metrics"}),(0,t.jsx)(n.p,{children:"The following lists the key GPU metrics collected by the DCGM Exporter:"})]}),"\n",(0,t.jsxs)(n.section,{className:"remark-sectionize-h3",children:[(0,t.jsx)(n.h3,{id:"node-level-metrics",children:"Node level metrics"}),(0,t.jsx)(n.p,{children:"It focuses on monitoring the GPU status for all Kubernetes nodes. These metrics are useful for assessing the overall GPU utilization of the cluster."}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DCGM_FI_DEV_GPU_UTIL"})," ",(0,t.jsx)("span",{class:"type",children:"Gauge"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"This metric represents the GPU utilization, displaying the current GPU usage as a percentage."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It monitors the GPU usage for all nodes in real time to help ensure proper resource allocation and load balancing."}),"\n"]}),"\n"]}),"\n","\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DCGM_FI_DEV_MEM_COPY_UTIL"})," ",(0,t.jsx)("span",{class:"type",children:"Gauge"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"This metric represents the memory usage, providing GPU memory bandwidth usage as a percentage."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It monitors the GPU memory resource usage to help detect and resolve memory bandwidth bottlenecks."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DCGM_FI_DEV_POWER_USAGE"})," ",(0,t.jsx)("span",{class:"type",children:"Gauge"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"This metric represents the current power consumption of the GPU in Watts (W)."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It monitors the GPU power usage to improve power efficiency and optimize operating costs."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DCGM_FI_DEV_TOTAL_ENERGY_CONSUMPTION"})," ",(0,t.jsx)("span",{class:"type",children:"Counter"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It measures the total accumulated GPU energy consumption in millijoules (mJ) since the system boot."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"By tracing the energy usage for all nodes to improve the long-term energy efficiency and establish the operational strategies."}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]}),"\n",(0,t.jsxs)(n.section,{className:"remark-sectionize-h3",children:[(0,t.jsx)(n.h3,{id:"container-level-metrics",children:"Container level metrics"}),(0,t.jsx)(n.p,{children:"It focuses on monitoring the GPU resource usage within individual containers. These metrics evaluate whether each container uses its allocated resources effectively."}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DCGM_FI_DEV_FB_FREE and DCGM_FI_DEV_FB_USED"})," ",(0,t.jsx)("span",{class:"type",children:"Gauge"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It displays the amount of available frame buffer memory and the amount of frame buffer memory in use, in MiB."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"By monitoring the GPU memory usage for each container, you can optimize memory resource allocation and prevent performance degradation due to resource shortage."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DCGM_FI_DEV_SM_CLOCK and DCGM_FI_DEV_MEM_CLOCK"})," ",(0,t.jsx)("span",{class:"type",children:"Gauge"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It displays the streaming multiprocessor (SM) clock frequency and memory clock frequency of each GPU in MHz."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It monitors GPU clock speeds of each container to help optimize the performance and set an appropriate frequency. This allows you to deliver the performance tailored to the needs of each application."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"DCGM_FI_DEV_GPU_TEMP and DCGM_FI_DEV_MEMORY_TEMP"})," ",(0,t.jsx)("span",{class:"type",children:"Gauge"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It measures the temperatures of each GPU and memory temperatures in degrees Celsius (C)."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"You can monitor the GPU temperatures of each container to prevent overheating and ensure stable operation. This extends the life of the system and reduces the downtime."}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>l});var t=s(96540);const i={},r=t.createContext(i);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);